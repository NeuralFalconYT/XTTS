{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmcx3KcNaq5_"
      },
      "source": [
        "[XTTS Huggingspace](https://huggingface.co/spaces/coqui/xtts)\n",
        "\n",
        "[Online audio cutter](https://mp3cut.net/)\n",
        "\n",
        "[Remove vocal from audio](https://vocalremover.org/https://vocalremover.org/)\n",
        "\n",
        "[Enhance audio](https://podcast.adobe.com/enhance)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path=\"/content\"\n",
        "# base_path=\".\""
      ],
      "metadata": {
        "id": "ZbiFKgYv7bM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H75I9ihcRwok",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install XTTS (It will take few minutes)\n",
        "\n",
        "# https://huggingface.co/spaces/coqui/xtts\n",
        "# https://docs.coqui.ai/en/dev/models/xtts.html\n",
        "\n",
        "!pip install huggingface-hub\n",
        "!rm -rf $base_path/TTS\n",
        "!rm -rf $base_path/XTTS-v2\n",
        "\n",
        "%cd $base_path\n",
        "!git clone https://github.com/coqui-ai/TTS/\n",
        "\n",
        "%cd $base_path/TTS\n",
        "!make system-deps\n",
        "!make install\n",
        "\n",
        "%cd $base_path\n",
        "# !git lfs install\n",
        "# !git clone https://huggingface.co/coqui/XTTS-v2\n",
        "\n",
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(repo_id=\"coqui/XTTS-v2\",local_dir=f\"{base_path}/XTTS-v2\")\n",
        "\n",
        "!pip install numpy==1.26.2\n",
        "!pip install tensorflow==2.12.0\n",
        "!sudo apt install libcairo2-dev pkg-config python3-dev\n",
        "!pip install pycairo\n",
        "!pip install nltk\n",
        "!pip install indic-nlp-library\n",
        "!pip install deep_translator==1.11.4\n",
        "!pip install gradio\n",
        "!pip install pydub\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "#@title Restart Runtime\n",
        "import time\n",
        "time.sleep(6)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #After disconnect run from Here"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SSZpG_OaIzJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <-- Tap this if you play on Mobile { display-mode: \"form\" }\n",
        "\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then run the cell below</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "tcneqMqy7kqz",
        "outputId": "40955796-7e0e-470d-ffc7-7950dc5a0448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<b>Press play on the music player to keep the tab alive, then run the cell below</b><br/>\n",
              "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path='/content'\n",
        "# base_path=\".\""
      ],
      "metadata": {
        "id": "QxwoXlG6orYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Model\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import uuid\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from indicnlp.tokenize.sentence_tokenize import sentence_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def get_chunks(paragraph,Language, max_chars=100, further_chunks=True):\n",
        "    global tokenizer_languages,languages\n",
        "\n",
        "    # Map of language codes to NLTK and Indic NLP library language tokenizers\n",
        "\n",
        "    lang=languages[Language]\n",
        "    # Use Indic NLP for Hindi or NLTK's sentence tokenizer for other languages\n",
        "    if lang == 'hi':\n",
        "        sentences = sentence_split(paragraph, 'hi')\n",
        "    else:\n",
        "        nltk_lang = tokenizer_languages.get(lang, 'english')\n",
        "        sentences = sent_tokenize(paragraph, language=nltk_lang)\n",
        "\n",
        "    new_sentences = []\n",
        "    i = 0\n",
        "\n",
        "    while i < len(sentences):\n",
        "        if len(sentences[i]) > max_chars:\n",
        "            join_limit = 1\n",
        "        else:\n",
        "            join_limit = 1\n",
        "\n",
        "        # Join sentences up to the join limit\n",
        "        new_sentence = ' '.join(sentences[i:i + join_limit])\n",
        "\n",
        "        # Further chunk if enabled and the new sentence exceeds max_chars\n",
        "        if further_chunks and len(new_sentence) > max_chars:\n",
        "            # Split at commas to create smaller chunks\n",
        "            sub_sentences = new_sentence.split(',')\n",
        "            temp_sentence = ''\n",
        "            for j, part in enumerate(sub_sentences):\n",
        "                # Adding comma back for readability except for the last segment in the split\n",
        "                if j < len(sub_sentences) - 1:\n",
        "                    part = part.strip() + ','\n",
        "                else:\n",
        "                    part = part.strip()  # No trailing comma for the last part\n",
        "\n",
        "                # Check if adding the part exceeds max_chars\n",
        "                if len(temp_sentence + part) > max_chars:\n",
        "                    new_sentences.append(temp_sentence)\n",
        "                    temp_sentence = part\n",
        "                else:\n",
        "                    temp_sentence += ' ' + part if temp_sentence else part\n",
        "\n",
        "            # Add any remaining part as a sentence\n",
        "            if temp_sentence:\n",
        "                new_sentences.append(temp_sentence)\n",
        "        else:\n",
        "            new_sentences.append(new_sentence)\n",
        "\n",
        "        # Increment by the dynamic join limit\n",
        "        i += join_limit\n",
        "\n",
        "    return new_sentences\n",
        "\n",
        "languages = {\n",
        "    'English': 'en',\n",
        "    'Hindi': 'hi',\n",
        "    'Arabic': 'ar',\n",
        "    'Chinese': 'zh-cn',\n",
        "    'Czech': 'cs',\n",
        "    'Dutch': 'nl',\n",
        "    'French': 'fr',\n",
        "    'German': 'de',\n",
        "    'Hungarian': 'hu',\n",
        "    'Italian': 'it',\n",
        "    'Japanese': 'ja',\n",
        "    'Korean': 'ko',\n",
        "    'Polish': 'pl',\n",
        "    'Portuguese': 'pt',\n",
        "    'Russian': 'ru',\n",
        "    'Spanish': 'es',\n",
        "    'Turkish': 'tr'\n",
        "}\n",
        "\n",
        "tokenizer_languages = {\n",
        "    'en': 'english',\n",
        "    'es': 'spanish',\n",
        "    'fr': 'french',\n",
        "    'de': 'german',\n",
        "    'it': 'italian',\n",
        "    'pt': 'portuguese',\n",
        "    'pl': 'polish',\n",
        "    'tr': 'turkish',\n",
        "    'ru': 'russian',\n",
        "    'nl': 'dutch',\n",
        "    'cs': 'czech',\n",
        "    'ar': 'arabic',\n",
        "    'zh-cn': 'chinese',\n",
        "    'ja': 'japanese',\n",
        "    'hu': 'hungarian',\n",
        "    'ko': 'korean',\n",
        "    'hi': 'hindi'  # Indic NLP library will handle Hindi tokenization\n",
        "}\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def translate_text(text, Language):\n",
        "    global languages\n",
        "    target_language=languages[Language]\n",
        "    if Language == \"Chinese\":\n",
        "          target_language='zh-CN'\n",
        "    translator = GoogleTranslator(target=target_language)\n",
        "    translation = translator.translate(text.strip())\n",
        "    t_text=str(translation)\n",
        "    return t_text\n",
        "\n",
        "def xtts(Enter_text,save_path,reference_voice_path,language,translate_text_flag):\n",
        "  global languages\n",
        "  if translate_text_flag==True:\n",
        "    temp_text=translate_text(Enter_text, language)\n",
        "    text=temp_text\n",
        "  else:\n",
        "    text=Enter_text\n",
        "  tts.tts_to_file(text=text,\n",
        "                file_path=save_path,\n",
        "                speaker_wav=reference_voice_path,\n",
        "                language=languages[language])\n",
        "  return save_path\n",
        "\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def merge_audio_files(file_paths, output_path):\n",
        "    # Create an empty AudioSegment object to store the merged audio\n",
        "    merged_audio = AudioSegment.silent(duration=0)\n",
        "\n",
        "    # Iterate through the list of audio file paths and append each to the merged_audio\n",
        "    for file_path in file_paths:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        merged_audio += audio\n",
        "\n",
        "    # Export the merged audio to the specified output_path\n",
        "    merged_audio.export(output_path, format=\"wav\")\n",
        "\n",
        "\n",
        "import re\n",
        "def clean_file_name(file_path):\n",
        "    # Get the base file name and extension\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_name, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "    # Replace non-alphanumeric characters with an underscore\n",
        "    cleaned = re.sub(r'[^a-zA-Z\\d]+', '_', file_name)\n",
        "\n",
        "    # Remove any multiple underscores\n",
        "    clean_file_name = re.sub(r'_+', '_', cleaned).strip('_')\n",
        "\n",
        "    # Generate a random UUID for uniqueness\n",
        "    random_uuid = uuid.uuid4().hex[:6]\n",
        "\n",
        "    # Combine cleaned file name with the original extension\n",
        "    clean_file_path = os.path.join(os.path.dirname(file_path), clean_file_name + f\"_{random_uuid}\" + file_extension)\n",
        "\n",
        "    return clean_file_path\n",
        "def get_new_tts_file_name(text):\n",
        "    global temp_save_folder\n",
        "    if text.endswith(\".\"):\n",
        "        text = text[:-1]\n",
        "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
        "    temp_name = f\"{temp_save_folder}/{truncated_text}.wav\"\n",
        "    audio_file_name = clean_file_name(temp_name)\n",
        "    return audio_file_name\n",
        "\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import os\n",
        "\n",
        "def remove_silence(file_path):\n",
        "    output_path=file_path.replace(\".wav\",\"_remove silence.wav\")\n",
        "    # Extract file name and format from the provided path\n",
        "    file_name = os.path.basename(file_path)\n",
        "    audio_format = \"wav\"\n",
        "\n",
        "    # Reading and splitting the audio file into chunks\n",
        "    sound = AudioSegment.from_file(file_path, format=audio_format)\n",
        "    audio_chunks = split_on_silence(sound,\n",
        "                                    min_silence_len=100,\n",
        "                                    silence_thresh=-45,\n",
        "                                    keep_silence=50)\n",
        "\n",
        "    # Putting the file back together\n",
        "    combined = AudioSegment.empty()\n",
        "    for chunk in audio_chunks:\n",
        "        combined += chunk\n",
        "\n",
        "\n",
        "    combined.export(output_path, format=audio_format)\n",
        "    print(\"Remove Silence Done\")\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def voice_clone(input_text,reference_audio_path,language,translate_text_flag,remove_silence_flag):\n",
        "  global temp_save_folder\n",
        "  chunks_folder=f\"{temp_save_folder}/temp_clone_tts/\"\n",
        "  if os.path.exists(chunks_folder):\n",
        "    shutil.rmtree(chunks_folder)\n",
        "  os.mkdir(chunks_folder)\n",
        "  sentences=get_chunks(input_text,language, max_chars=100, further_chunks=True)\n",
        "  clone_chunk=[]\n",
        "  for index, text in enumerate(sentences):\n",
        "    temp_save_path=f\"{chunks_folder}/{index}.wav\"\n",
        "    xtts(text,temp_save_path,reference_audio_path,language,translate_text_flag)\n",
        "    if os.path.exists(temp_save_path):\n",
        "      clone_chunk.append(temp_save_path)\n",
        "  save_path=get_new_tts_file_name(input_text)\n",
        "  merge_audio_files(clone_chunk, save_path)\n",
        "  if os.path.exists(save_path):\n",
        "    if remove_silence_flag:\n",
        "      output_path=remove_silence(save_path)\n",
        "      return output_path\n",
        "    else:\n",
        "      return save_path\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "#import tts\n",
        "%cd $base_path\n",
        "from TTS.api import TTS\n",
        "tts = TTS(model_path=f\"{base_path}/XTTS-v2/\", config_path=f\"{base_path}/XTTS-v2/config.json\", progress_bar=True, gpu=True)\n",
        "temp_save_folder=f\"{base_path}/clone_tts\"\n",
        "if not os.path.exists(temp_save_folder):\n",
        "  os.mkdir(temp_save_folder)\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "fPUs9Thmo3RF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Gradio Interface\n",
        "import gradio as gr\n",
        "def gradio_call(Reference_Audio_Path,TTS_Text,Language,Auto_Translate,Remove_Silence):\n",
        "  clone_audio_path=voice_clone(TTS_Text,Reference_Audio_Path,Language,Auto_Translate,Remove_Silence)\n",
        "  return clone_audio_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    # gr.Markdown(f\"\"\"# XTTS-V2 Voice Clone\n",
        "    # [Online Audio Cutter](https://mp3cut.net/)\n",
        "    # \"\"\")\n",
        "    gr.Markdown(f\"\"\"<div style=\"text-align: center;\">\n",
        "    <h1><a href=\"https://huggingface.co/coqui/XTTS-v2\" style=\"text-decoration: none; color: orange;\">XTTS-V2 Voice Clone</a></h1>\n",
        "    <a href=\"https://mp3cut.net/\" style=\"text-decoration: none; color: blue;\">Online Audio Cutter</a>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "    audio_file=gr.Audio(label=\"Reference Audio\", type=\"filepath\")\n",
        "    input_text = gr.Textbox(label=\"Text to Generate\", lines=6)\n",
        "    language_name=gr.Dropdown(label=\"Language\",choices=['English', 'Hindi', 'Arabic', 'Chinese', 'Czech', 'Dutch', 'French', 'German', 'Hungarian', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Spanish', 'Turkish'],value=\"English\")\n",
        "    generate_btn = gr.Button(\"Synthesize\", variant=\"primary\")\n",
        "    with gr.Accordion(\"Advanced Settings\", open=False):\n",
        "        auto_translate=gr.Checkbox(value=True,label=\"Auto Translate\")\n",
        "        no_silence=gr.Checkbox(value=True,label=\"Remove Silence\")\n",
        "    audio_output  = gr.Audio(label=\"Generated Audio\")\n",
        "    generate_btn.click(\n",
        "      gradio_call,\n",
        "      inputs=[audio_file,input_text,language_name,auto_translate,no_silence],\n",
        "      outputs=[audio_output],\n",
        "  )\n",
        "demo.launch(debug=False,share=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GQKICYD6E5Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Xrv4f85JXQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3uRFXxnmJXNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMVrufRkJXKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZkQEZBUJXG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaQk1OGAJXD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uq5rICjGZLAP",
        "outputId": "cc2abf4d-4e74-4073-fb51-58de7b203490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/user_upload/sanji_2_c51313.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#@title Upload 6s Audio clip\n",
        "\n",
        "# import os\n",
        "# from google.colab import files\n",
        "# from IPython.display import clear_output\n",
        "# import uuid\n",
        "# def upload_audio():\n",
        "#     upload_folder = f\"{base_path}/user_upload\"\n",
        "\n",
        "#     os.makedirs(upload_folder, exist_ok=True)\n",
        "\n",
        "#     os.chdir(upload_folder)\n",
        "\n",
        "#     uploaded = files.upload()\n",
        "\n",
        "#     os.chdir(base_path)\n",
        "\n",
        "#     audio_name_list = []\n",
        "\n",
        "#     for fn in uploaded.keys():\n",
        "#         file_path = f\"{upload_folder}/{fn}\"\n",
        "#         save_file_path = clean_file_name(file_path)\n",
        "\n",
        "#         os.rename(file_path, save_file_path)\n",
        "#         audio_name_list.append(save_file_path)\n",
        "\n",
        "#     audio_extensions = ('.wav', '.mp3')\n",
        "#     valid_audio_files = [f for f in audio_name_list if f.lower().endswith(audio_extensions)]\n",
        "\n",
        "#     clear_output()\n",
        "\n",
        "#     if valid_audio_files:\n",
        "#         return valid_audio_files[0]\n",
        "#     else:\n",
        "#         print(\"Please upload an audio file.\")\n",
        "#         return None\n",
        "# upload_audio()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run as funtion\n",
        "# Text = 'Hi how are you'  # @param {type: \"string\"}\n",
        "# Reference_Audio = '/content/a.mp3'  # @param {type: \"string\"}\n",
        "# Language = \"English\" #@param ['English', 'Hindi', 'Arabic', 'Chinese', 'Czech', 'Dutch', 'French', 'German', 'Hungarian', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Spanish', 'Turkish']\n",
        "# Auto_Translate = True  # @param {type: \"boolean\"}\n",
        "# Remove_Silence= True  # @param {type: \"boolean\"}\n",
        "# clone_audio_path=voice_clone(Text,Reference_Audio,Language,Auto_Translate,Remove_Silence)\n",
        "# from IPython.display import Audio,display\n",
        "# display(Audio(clone_audio_path, autoplay=False))"
      ],
      "metadata": {
        "id": "icEiEBq_werg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download(clone_audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-sulCNNMHmfx",
        "outputId": "7a2063e9-bd9a-4c09-f07c-10ecce9a05d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6646dd11-4f99-4e93-8539-65f38312f63c\", \"Hi_how_are_you_343d9e_remove silence.wav\", 115806)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7euA1A03_45"
      },
      "source": [
        "\n",
        "[Audio Cutter](https://mp3cut.net/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}